{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Parse a Sample File of ITCH Messages\n",
    "--- \n",
    "[GITHUB](https://github.com/PacktPublishing/Machine-Learning-for-Algorithmic-Trading-Second-Edition/blob/master/02_market_and_fundamental_data/01_NASDAQ_TotalView-ITCH_Order_Book/01_parse_itch_order_flow_messages.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip\n",
    "import shutil \n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from matplotlib.ticker import FuncFormatter \n",
    "from struct import unpack\n",
    "from collections import namedtuple, Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import urljoin\n",
    "from datetime import timedelta\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    \"\"\"Return a formatted time string 'HH:MM:SS\n",
    "    based on a numeric time() value\"\"\"\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f'{h:0>2.0f}:{m:0>2.0f}:{s:0>5.2f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITCH Format Settings\n",
    "---\n",
    "### From [message_types.xlsx](message_types.xlsx)\n",
    "### [`struct`](https://docs.python.org/3/library/struct.html) module for binary data \n",
    "- ITCH tick data comes in binary format \n",
    "- `struct` parses binary data using format strings \n",
    "    - identifies the message element by indicating length and type of various components of the byte string \n",
    "    - conversions between Python values and C structs represented as Python byte objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Format Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_codes = {'O' : 'Start of Message', \n",
    "            'S' : 'Start of System Hours', \n",
    "            'Q' : 'Start of Market Hours',\n",
    "            'M' : 'End of Market Hours', \n",
    "            'E' : 'End of System Hours', \n",
    "            'C' : 'End of Messages'}\n",
    "\n",
    "encoding = {'primary_market_maker': {'Y': 1, 'N': 0},\n",
    "        'printable'           : {'Y': 1, 'N': 0},\n",
    "        'buy_sell_indicator'  : {'B': 1, 'S': -1},\n",
    "        'cross_type'          : {'O': 0, 'C': 1, 'H': 2},\n",
    "        'imbalance_direction' : {'B': 0, 'S': 1, 'N': 0, 'O': -1}}\n",
    "\n",
    "# Assembles Format Strings According to the Formats Dictionary \n",
    "formats = {\n",
    "    ('integer', 2): 'H',  #int of length 2 -> format string 'H'\n",
    "    ('integer', 4): 'I',\n",
    "    ('integer', 6): '6s',  #int of length 6 -> parse as string, convert later\n",
    "    ('integer', 8): 'Q',\n",
    "    ('alpha',   1): 's',\n",
    "    ('alpha',   2): '2s',\n",
    "    ('alpha',   4): '4s',\n",
    "    ('alpha',   8): '8s',\n",
    "    ('price_4', 4): 'I',\n",
    "    ('price_8', 8): 'Q',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Message Specs for Binary Data Parser \n",
    "### Load Message Types \n",
    "- `message_types.xlxs` contains messasge type specs (per [ITCH Protocol Documentation](https://www.nasdaqtrader.com/content/technicalsupport/specifications/dataproducts/NQTVITCHSpecification.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = (pd.read_excel('message_types.xlsx', sheet_name='messages')\n",
    "                .sort_values('id')\n",
    "                .drop('id', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Message Types\n",
    "- function `clean_message_types()` runs basic cleaning steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message_types(df): \n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "    df.value = df.value.str.strip()\n",
    "    df.name = (df.name\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .str.replace(' ','_')\n",
    "            .str.replace('-','_')\n",
    "            .str.replace('/','_'))\n",
    "    df.notes = df.notes.str.strip()\n",
    "    df['message_type'] = df.loc[df.name == 'message_type', 'value'] \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types = clean_message_types(message_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Message Labels\n",
    "- extract message type codes and names to make results more readable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_labels = (message_types.loc[:, ['message_type', 'notes']]\n",
    "                    .dropna()\n",
    "                    .rename(columns={'notes':'name'}))\n",
    "\n",
    "message_labels.name = (message_labels.name\n",
    "                    .str.lower()\n",
    "                    .str.replace('message','')\n",
    "                    .str.replace('.','')\n",
    "                    .str.strip().str.replace(' ','_'))\n",
    "\n",
    "message_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Specification Details \n",
    "- [Struct](https://docs.python.org/3/library/struct.html) Module: use format information to parse binary source data \n",
    "- Messages consist of fields defined by offset, length, and type of value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Option to Reload Cleaned `message_types.xlsx` from `.csv` File*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types.to_csv('message_types.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types = pd.read_csv('message_types.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Message Specs info Format Strings and `namedtuples` that Capture Message Content \n",
    "- create `(type, length)` formatting tupes from ITCH specs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_types.loc[:, 'formats'] = (message_types[['value', 'length']].apply(tuple, axis=1).map(formats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extract formatting details for alphanumerical fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_fields = message_types[message_types.value == 'alpha'].set_index('name')\n",
    "alpha_msgs = alpha_fields.groupby('message_type')\n",
    "alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}\n",
    "alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate message classes as named tuples and format strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_fields, fstring = {}, {}\n",
    "for t, message in message_types.groupby('message_type'): \n",
    "    message_fields[t] = namedtuple(typename=t, field_names=message.name.tolist())\n",
    "    fstring[t] = '>' + ''.join(message.formats.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_fields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_fields.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing\n",
    "- required by fields of `alpha` type (alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_alpha(mtype, data): \n",
    "    ''' \n",
    "    Process byte strings of type alpha\n",
    "    '''\n",
    "\n",
    "    for col in alpha_formats.get(mtype).keys(): \n",
    "        if mtype != 'R' and col == 'stock': \n",
    "            data = data.drop(col, axis=1)\n",
    "            continue \n",
    "        data.loc[: col] = data.loc[:, col].str.decode(\"utf-8\").str.strip()\n",
    "        if encoding.get(col): \n",
    "            data.loc[:, col] = data.loc[:, col].map(encoding.get(col))\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get NASDAQ ITCH Data from FTP Server \n",
    "--- \n",
    "### From [Binary ITCH Data](data/)\n",
    "- Nasdaq offers samples of daily binary files for several months \n",
    "- parse a sample file of ITCH messages \n",
    "- reconstruct executed trades and the order book for any given tick \n",
    "- Large Dataset (time and memory space 16GB+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Data Paths\n",
    "- store data in `data` subdirectory and convert result to `hdf` format \n",
    "- Sample Files: [NASDAQ ftp server](ftp://emi.nasdaq.com/ITCH/)\n",
    "- `FTP_URL` changed from 'ftp://...' to 'https://emi.nasdaq.com/ITCH/Nasdaq%20ITCH/' per [forum](https://exchange.ml4trading.io/t/chapter-2-nasdaq-itch-ftp-error/626/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data') # SET TO EXTERNAL HARDDRIVE -> LARGE DATASET\n",
    "itch_store = str(data_path / 'itch.h5')\n",
    "order_book_store = data_path / 'order_book.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample FTP Address, filename and corresponding date used in example\n",
    "FTP_URL = 'https://emi.nasdaq.com/ITCH/Nasdaq%20ITCH/'\n",
    "SOURCE_FILE = '10302019.NASDAQ_ITCH50.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Unzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def may_be_downloaded(url): \n",
    "    ''' \n",
    "    Download and Unzip ITCH Data if Not Yet Avaliable\n",
    "    '''\n",
    "    if not data_path.exists(): \n",
    "        print('Creating Directory')\n",
    "        data_path.mkdir()\n",
    "    else: \n",
    "        print('Directory Exists')\n",
    "    \n",
    "    filename = data_path / url.split('/')[-1]\n",
    "    if not filename.exists(): \n",
    "        print('Downloading...', url)\n",
    "        urlretrieve(url,filename)\n",
    "    else: \n",
    "        print('File Exists')\n",
    "    \n",
    "    unzipped = data_path / (filename.stem + '.bin')\n",
    "    if not unzipped.exists(): \n",
    "        print('Unzipping to', unzipped)\n",
    "        with gzip.open(str(filename), 'rb') as f_in: \n",
    "            with open(unzipped, 'wb') as f_out: \n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    else: \n",
    "        print('File Already Unpacked')\n",
    "    \n",
    "    return unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = may_be_downloaded(urljoin(FTP_URL, SOURCE_FILE))\n",
    "date = file_name.name.split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Binary Message Data \n",
    "---\n",
    "- binary file for single day contains over **350,000,000** *worth over 12GB*\n",
    "- appends parsed result iteratively to a file in the fast HDF5 format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import byteorder\n",
    "\n",
    "\n",
    "def store_messages(m): \n",
    "    ''' \n",
    "    Handle Occasional Storing of All Messages\n",
    "    '''\n",
    "\n",
    "    with pd.HDFStore(itch_store) as store: \n",
    "        for mtype, data in m.items(): \n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "            # Parse Timestamp Info\n",
    "            data.timestamp = data.timestamp.apply(int.from_bytes, byteorder='big')\n",
    "            data.timestamp = pd.to_timedelta(data.timestamp)\n",
    "\n",
    "            # Alpha Formatting \n",
    "            if mtype in alpha_formats.key():\n",
    "                data = format_alpha(mtype, data)\n",
    "            \n",
    "            s = alpha_length.get(mtype)\n",
    "            if s: \n",
    "                s = {c: s.get(c) for c in data.columns}\n",
    "            dc = ['stock_locate']\n",
    "            if m =='R': \n",
    "                dc.append('stock')\n",
    "            try: \n",
    "                store.append(mtype, data, format='t', min_itemsize=s, data_columns=dc)\n",
    "            \n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "                print(mtype)\n",
    "                print(data.info())\n",
    "                print(pd.Series(list(m.keys())).value_counts())\n",
    "                data.to_csv('data.csv', index=False)\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = defaultdict(list)\n",
    "message_count = 0 \n",
    "message_type_counter = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- processes binary file and produces parsed orders stored by message type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "with file_name.open('rb') as data: \n",
    "    while True: \n",
    "\n",
    "        # determine message size (in bytes)\n",
    "        message_size = int.from_bytes(data.read(2), byteorder='big', signed=False)\n",
    "\n",
    "        # message type from first byte \n",
    "        message_type = data.read(1).decode('ascii')\n",
    "        message_type_counter.update([message_type])\n",
    "\n",
    "        # read and store message \n",
    "        try: \n",
    "            record = data.read(message_size - 1)\n",
    "            message = message_fields[message_type]._make(unpack(fstring[message_type], record))\n",
    "            messages[message_type].append(message)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print(message_type)\n",
    "            print(record)\n",
    "            print(fstring[message_type])\n",
    "\n",
    "        # System Events \n",
    "        if message_type == 'S': \n",
    "            seconds = int.from_bytes(message.timestamp, byteorder='big') * 1e-9 \n",
    "            print('\\n', event_codes.get(message.event_code.decode('ascii'), 'Error'))\n",
    "            print(f'\\t{format_time(seconds)}\\t{message_count:12,.0f}')\n",
    "            if message.event_code.decode('ascii') == 'C': \n",
    "                store_messages(message)\n",
    "                break \n",
    "        message_count += 1 \n",
    "\n",
    "\n",
    "        if message_count % 2.5e7 == 0: \n",
    "            seconds = int.from_bytes(message.timestamp, byteorder='big') * 1e-9\n",
    "            d = format_time(time() - start) \n",
    "            print(f'\\t{format_time(seconds)}\\t{message_count:12,.0f}\\t{d}')\n",
    "            res = store_messages(messages)\n",
    "            if res == 1: \n",
    "                print(pd.Series(dict(message_type_counter)).sort_values())\n",
    "                break \n",
    "            messages.clear() \n",
    "\n",
    "print('Duration: ', format_time(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Trading Day via [ITCH data](data/) and [message_types.csv](message_types.csv)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = pd.Series(message_type_counter).to_frame('# Trades')\n",
    "counter['Message Type'] = counter.index.map(message_labels.set_index('message_type').name.to_dict())\n",
    "counter = counter[['Message Type', '# Trades']].sort_values('# Trades', ascending=False)\n",
    "counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store: \n",
    "    store.put('summary', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Equities by Traded Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store: \n",
    "    stocks = store['R'].loc[:, ['stock_locate', 'stock']]\n",
    "    trades = store['P'].append(store['Q'].rename(columns={'cross_price' : 'price'}), sort=False).merge(stocks)\n",
    "\n",
    "trades['value'] = trades.shares.mul(trades.price)\n",
    "trades['value_share'] = trades.value.div(trades.value.sum())\n",
    "\n",
    "trade_summary = trades.groupby('stock').value_share.sum().sort_values(ascending=False)\n",
    "trade_summary.iloc[:50].plot.bar(figsize=(14,6), color='darkblue', title='Share of Traded Value')\n",
    "\n",
    "plt.gct().yaxis.set_major_formatter(FuncFormatter(lamda y, _ : '{:.0%}'.format(y)))\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08a0dfaf3fa74e1b9a1bb705dbe1b2708914f992320bdd77350db063c3b717dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
